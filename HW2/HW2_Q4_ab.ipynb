{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hjRM13EAuL3g"
   },
   "source": [
    "# HW2 - Q4: Training a robust model & Tighter Certification (10 points)\n",
    "\n",
    "**Keywords**: Adversarial Robustness Training\n",
    "\n",
    "**About the dataset**: \\\n",
    "The [MNIST](https://en.wikipedia.org/wiki/MNIST_database) database (Modified National Institute of Standards and Technology database) is a large database of handwritten digits that is commonly used for training various image processing systems.\\\n",
    "The MNIST database contains 70,000 labeled images. Each datapoint is a $28\\times 28$ pixels grayscale image.\n",
    "\n",
    "**Agenda**:\n",
    "* In this programming challenge, you will train a 2-hidden layer neural network which is robust to adversarial attacks. \n",
    "* You will train models on adversarial examples generated using both FGSM and PGD.\n",
    "* Finally, you will compare the robustness of a standard (non-robust) model vs. the robust models using both IBP and FastLin bound Algorithms.\n",
    "\n",
    "\n",
    "**Note:**\n",
    "* **It is recommended that you use GPU hardware accelaration for this question.**\n",
    "* A note on working with GPU:\n",
    "  * Take care that whenever declaring new tensors, set `device=device` in parameters. \n",
    "  * You can also move a declared torch tensor/model to device using `.to(device)`. \n",
    "  * To move a torch model/tensor to cpu, use `.to('cpu')`\n",
    "  * Keep in mind that all the tensors/model involved in a computation have to be on the same device (CPU/GPU).\n",
    "* Run all the cells in order.\n",
    "* **Do not edit** the cells marked with !!DO NOT EDIT!!\n",
    "* Only **add your code** to cells marked with !!!! YOUR CODE HERE !!!!\n",
    "* Do not change variable names, and use the names which are suggested."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZUJgYttwjmpK"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bFWii5HbsA4r"
   },
   "source": [
    "## Preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N1FBs7WdqrID",
    "outputId": "c3f4db52-a577-461d-8f69-457eeebe0da0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: gdown in /usr/local/lib/python3.8/dist-packages (4.4.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from gdown) (3.8.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from gdown) (1.15.0)\n",
      "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.8/dist-packages (from gdown) (2.23.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from gdown) (4.64.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from gdown) (4.6.3)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (2022.9.24)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (3.0.4)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
     ]
    }
   ],
   "source": [
    "# install this library\n",
    "!pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-05-13T02:49:35.930120Z",
     "iopub.status.busy": "2022-05-13T02:49:35.929583Z",
     "iopub.status.idle": "2022-05-13T02:49:45.968342Z",
     "shell.execute_reply": "2022-05-13T02:49:45.967617Z",
     "shell.execute_reply.started": "2022-05-13T02:49:35.930035Z"
    },
    "id": "qNtGmOhl1I_m",
    "outputId": "ae1f0a64-e4a1-4e71-938e-6847b1da55c5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://bit.ly/3sKvyOs\n",
      "To: /content/nn_model.pt\n",
      "100%|██████████| 7.46M/7.46M [00:00<00:00, 154MB/s]\n",
      "Downloading...\n",
      "From: https://bit.ly/3lsVcDn\n",
      "To: /content/models.zip\n",
      "100%|██████████| 1.55k/1.55k [00:00<00:00, 4.62MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained model (nn_model): NN_Model(\n",
      "  (l1): Linear(in_features=784, out_features=1024, bias=True)\n",
      "  (l2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "  (l3): Linear(in_features=1024, out_features=10, bias=True)\n",
      ")\n",
      "Dummy model (test_model): Test_Model(\n",
      "  (l1): Linear(in_features=2, out_features=3, bias=True)\n",
      "  (l2): Linear(in_features=3, out_features=3, bias=True)\n",
      "  (l3): Linear(in_features=3, out_features=2, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# !!DO NOT EDIT!!\n",
    "# imports \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import requests\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import gdown\n",
    "from zipfile import ZipFile\n",
    "\n",
    "# set device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# loading the dataset full MNIST dataset\n",
    "mnist_train = datasets.MNIST(\"./data\", train=True, download=True, transform=transforms.ToTensor())\n",
    "mnist_test = datasets.MNIST(\"./data\", train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "mnist_train.data = mnist_train.data.to(device)\n",
    "mnist_test.data = mnist_test.data.to(device)\n",
    "\n",
    "mnist_train.targets = mnist_train.targets.to(device)\n",
    "mnist_test.targets = mnist_test.targets.to(device)\n",
    "\n",
    "# reshape and min-max scale\n",
    "X_train =  (mnist_train.data.reshape((mnist_train.data.shape[0], -1))/255).to(device)\n",
    "y_train = mnist_train.targets\n",
    "X_test = (mnist_test.data.reshape((mnist_test.data.shape[0], -1))/255).to(device)\n",
    "y_test = mnist_test.targets\n",
    "\n",
    "# load pretrained and dummy model\n",
    "url_nn_model = 'https://bit.ly/3sKvyOs'\n",
    "url_models   = 'https://bit.ly/3lsVcDn'\n",
    "gdown.download(url_nn_model, 'nn_model.pt')\n",
    "gdown.download(url_models, 'models.zip')\n",
    "ZipFile(\"models.zip\").extractall(\"./\")\n",
    "\n",
    "from model import NN_Model\n",
    "from test_model import Test_Model\n",
    "nn_model = torch.load(\"./nn_model.pt\").to(device)\n",
    "print('Pretrained model (nn_model):', nn_model)\n",
    "\n",
    "test_model = Test_Model()\n",
    "print('Dummy model (test_model):', test_model)\n",
    "\n",
    "# This will save the linear layers of the neural network model in a ordered list\n",
    "# Eg:\n",
    "# to access weight of first layer: model_layers[0].weight\n",
    "# to access bias of first layer: model_layers[0].bias\n",
    "model_layers = [layer for layer in nn_model.children()] # for nn_model\n",
    "test_model_layers = [layer for layer in test_model.children()] # for dummy model\n",
    "\n",
    "# first few examples\n",
    "example_data = mnist_test.data[:18]/255\n",
    "example_data_flattened  = example_data.view((example_data.shape[0], -1)).to(device) # needed for training\n",
    "example_labels = mnist_test.targets[:18].to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qBFXtet3mnXM"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lu9K75vp9nI6"
   },
   "source": [
    "### **Adversarial training:** In order to train robust models, the most intuitive strategy is to train on adversarial examples.\n",
    "* The adversarial (robust) loss function is defined as:\n",
    "$\\underset{\\theta}{minimize} \\frac{1}{|S|}\\sum_{x,y\\in S} \\underset{∥δ∥≤ϵ}{max}\\,ℓ(h_θ(x+δ),y)$, \\\n",
    "where $\\theta$ are the learnable parameters, $S$ is the set of training examples with $x$ representing the input example and $y$ the ground truth label, $h_\\theta$ is the hypothesis (neural network model), $\\delta$ is the attack perturbation, and $\\epsilon$ is the attack budget.\n",
    "\n",
    "* This is also known as the min-max loss function. The gradient descent step now becomes:\\\n",
    "$\\theta:=\\theta-\\frac{\\alpha}{|B|}\\sum_{x,y\\in B} ∇_θ \\underset{∥δ∥≤ϵ}{max}\\,ℓ(h_θ(x+δ),y)$,\\\n",
    "where $B$ is the mini-batch and $\\alpha$ is the learning rate. \n",
    "\n",
    "* Now the question becomes how to find the inner term: $∇_θ \\underset{∥δ∥≤ϵ}{max}\\,ℓ(h_θ(x+δ),y)$ of the gradient descent step. For this, we can use **Danskin’s Theorem**, which states that to compute the (sub)gradient of a function containing a max term, we need to simply 1) find the maximum, and 2) compute the normal gradient evaluated at this point. It holds only when you have the exact maximum.  Note that it is not possible to solve the inner maximization problem exactly (NP-hard). However, the better job we do of solving the inner maximization problem, the closer it seems that Danskin’s theorem starts to hold. That is why we can re-use methods such as FGSM/PGD to find approximate worst case examples. In other words, we can perform the attack to find $δ^{*} = \\underset{∥δ∥≤ϵ}{argmax}ℓ(h_θ(x+δ),y)$, and then compute this term at the perturbed image: $∇_θℓ(h_θ(x+δ^{*}),y)$.\n",
    "\n",
    "In summary, we would create an adversarial example for each datapoint in the mini-batch and add the loss corresponding to that example to the gradient.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cOLLgUNtuHtk"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2oxntXnpDG0y"
   },
   "source": [
    "### **(a) Setup:** (2 points)\n",
    "### **#1.**Get the attack functions `fgsm` and `pgd` that you defined in the HW2-Q3 (a) and (b). Modify the `pgd` function to start with random values of `delta` instead of zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T03:19:05.822659Z",
     "iopub.status.busy": "2022-05-13T03:19:05.822355Z",
     "iopub.status.idle": "2022-05-13T03:19:05.832077Z",
     "shell.execute_reply": "2022-05-13T03:19:05.831363Z",
     "shell.execute_reply.started": "2022-05-13T03:19:05.822616Z"
    },
    "id": "jY92MjbEDGf9"
   },
   "outputs": [],
   "source": [
    "#######\n",
    "# !!! YOUR CODE HERE !!!\n",
    "import torch.nn as nn\n",
    "def fgsm(model, X, y, epsilon = 0.05):\n",
    "    # Setting tensor parameters\n",
    "    X = X.to(device)\n",
    "    y = y.to(device)\n",
    "    X.requires_grad = True\n",
    "\n",
    "    # setting initial perturbation tensor\n",
    "    perturbation = torch.zeros_like(X, requires_grad=True)\n",
    "\n",
    "    # reset gradients\n",
    "    model.zero_grad()\n",
    "\n",
    "    # getting predictions\n",
    "    y_pred = model(X + perturbation)\n",
    "\n",
    "    # calculate loss\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    loss = criterion(y_pred, y).to(device)\n",
    "\n",
    "    # backpropagate loss\n",
    "    loss.backward()\n",
    "\n",
    "    # calculate perturbation\n",
    "    perturbation = epsilon * (perturbation.grad.sign())\n",
    "    \n",
    "    return perturbation.detach()\n",
    "\n",
    "def pgd(model, X, y, alpha = 1000, epsilon = 0.05, num_iter = 1000):\n",
    "    \n",
    "    # Setting tensor parameters\n",
    "    X = X.to(device)\n",
    "    y = y.to(device)\n",
    "\n",
    "    # setting criterion for loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Setting initial random values of perturbation tensor\n",
    "    perturbation = torch.randn_like(X, requires_grad=True)\n",
    "\n",
    "    for i in range(num_iter):\n",
    "        X.requires_grad = True\n",
    "\n",
    "        # prediction \n",
    "        y_pred = model(X + perturbation)\n",
    "\n",
    "        # calculate loss\n",
    "        loss = criterion(y_pred, y).to(device)\n",
    "\n",
    "        # backpropagate loss\n",
    "        loss.backward()\n",
    "\n",
    "        # calculate perturbation\n",
    "        perturbation.data = torch.clamp((perturbation + X.shape[0]*alpha*perturbation.grad.data), min = -epsilon, max = epsilon)\n",
    "\n",
    "        # reset gradient\n",
    "        perturbation.grad.zero_()\n",
    "\n",
    "    return perturbation.detach()\n",
    "\n",
    "\n",
    "#######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hrHNjl-xDm7P"
   },
   "source": [
    "### **#2.** Create a 2-hidden-layer neural network model in pytorch. The input should be the size of the flattened MNIST image, and output layer should be of size 10, which is the number of target labels. Each of the two hidden layers should be of size 1024 with ReLU activations between each subsequent layer except the last layer.\n",
    "\n",
    "You can refer to the structure of `nn_model` from HW2-Q3. It should be similar to that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T02:50:18.439215Z",
     "iopub.status.busy": "2022-05-13T02:50:18.438466Z",
     "iopub.status.idle": "2022-05-13T02:50:18.446367Z",
     "shell.execute_reply": "2022-05-13T02:50:18.445636Z",
     "shell.execute_reply.started": "2022-05-13T02:50:18.439150Z"
    },
    "id": "b0J-mW8gDmYl"
   },
   "outputs": [],
   "source": [
    "#######\n",
    "# !!!! YOUR CODE HERE !!!!\n",
    "num_features = X_train.shape[1]\n",
    "num_classes = 10\n",
    "class NN_Model(torch.nn.Module):\n",
    "  def __init__(self):\n",
    "    super(NN_Model, self).__init__()\n",
    "    self.linear1 = nn.Linear(num_features, 1024)\n",
    "    self.linear2 = nn.Linear(1024, 1024)\n",
    "    self.linear3 = nn.Linear(1024, num_classes)\n",
    "\n",
    "    self.relu = nn.ReLU()    \n",
    "\n",
    "  def forward(self, X):\n",
    "    activation1 = self.relu(self.linear1(X))\n",
    "    activation2 = self.relu(self.linear2(activation1))\n",
    "    output = self.linear3(activation2)\n",
    "    return output\n",
    "#######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NYq0cTMSE1Ta"
   },
   "source": [
    "### **#3.** Define a function `train_torch_model_adversarial` that takes as input an initialized torch model (`model`), batch size (`batch_size`), initialized loss (`criterion`), max number of epochs (`max_epochs`), training data (`X_train, y_train`), learning rate (`lr`), tolerance for stopping (`tolerance`), adversarial strategy (`adversarial_strategy`: `None/'fgsm'/'pgd'`), and attack budget(`epsilon`). \n",
    "\n",
    "### **Note**: \n",
    "* If `adversarial_strategy` is `None`, don't train on adversarial examples.\n",
    "* This function will return a tuple of `(model, losses)`, where `model` is the trained model, and `losses` are a list of tuple of loss logged every epoch. \n",
    "* The only difference from the function `train_torch_model` that you wrote in HW2-Q2 (b) is that you also add gradient of adversarial example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T02:50:44.598192Z",
     "iopub.status.busy": "2022-05-13T02:50:44.597900Z",
     "iopub.status.idle": "2022-05-13T02:50:44.610522Z",
     "shell.execute_reply": "2022-05-13T02:50:44.609437Z",
     "shell.execute_reply.started": "2022-05-13T02:50:44.598160Z"
    },
    "id": "cJ22m_3uFwTK"
   },
   "outputs": [],
   "source": [
    "#######\n",
    "# !!!! YOUR CODE HERE !!!!\n",
    "# Define a function train_torch_model\n",
    "import math\n",
    "\n",
    "def train_torch_model(model, batch_size, criterion, max_epochs, X_train, y_train, lr, tolerance, adversarial_strategy, epsilon):\n",
    "  losses = []\n",
    "  prev_loss = float('inf')\n",
    "  number_of_batches = math.ceil(len(X_train)/batch_size)\n",
    "  \n",
    "  #######\n",
    "  # !!!! YOUR CODE HERE !!!!\n",
    "  # 3. move model to device\n",
    "  model = model.to(device)\n",
    "\n",
    "  # 4. define optimizer (use torch.optim.SGD (Stochastic Gradient Descent)) \n",
    "  # Set learning rate to lr and also set model parameters\n",
    "  optimizer = torch.optim.SGD(model.parameters(), lr = lr) \n",
    "\n",
    "  for epoch in tqdm(range(max_epochs)):\n",
    "    for i in range(number_of_batches):\n",
    "      X_train_batch = X_train[i*batch_size: (i+1)*batch_size]\n",
    "      y_train_batch = y_train[i*batch_size: (i+1)*batch_size]\n",
    "\n",
    "      # 5. reset gradients\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      if adversarial_strategy == None:\n",
    "        # 6. prediction\n",
    "        y_pred_batch = model(X_train_batch)\n",
    "\n",
    "        # 7. calculate loss\n",
    "        loss = criterion(y_pred_batch, y_train_batch)\n",
    "      \n",
    "      if adversarial_strategy == 'fgsm':\n",
    "        # 6. prediction\n",
    "        delta = fgsm(model, X_train_batch, y_train_batch, epsilon = 0.05)\n",
    "        y_pred_batch = model(X_train_batch + delta)\n",
    "  \n",
    "        # 7. calculate loss\n",
    "        loss = criterion(y_pred_batch, y_train_batch)\n",
    "\n",
    "      if adversarial_strategy == 'pgd':\n",
    "        # 6. prediction\n",
    "        delta = pgd(model, X_train_batch, y_train_batch, alpha = 0.01, epsilon = 0.05, num_iter = 100)\n",
    "        y_pred_batch = model(X_train_batch + delta)\n",
    "  \n",
    "        # 7. calculate loss\n",
    "        loss = criterion(y_pred_batch, y_train_batch)\n",
    "\n",
    "      # 8. backpropagate loss\n",
    "      loss.backward()\n",
    "\n",
    "      # 9. perform a single gradient update step\n",
    "      optimizer.step()\n",
    "\n",
    "  #######\n",
    "\n",
    "    # log loss every epoch and print every epoch:\n",
    "    losses.append((epoch, loss.item()))\n",
    "    print('Epoch: {}, Loss: {}'.format(epoch, loss.item()))\n",
    "    \n",
    "    # break if decrease in loss is less than threshold\n",
    "    if abs(prev_loss-loss)<=tolerance:\n",
    "      break\n",
    "    else:\n",
    "      prev_loss=loss  \n",
    "\n",
    "  # return updated model and logged losses\n",
    "  return model, losses\n",
    "#######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kOiOT9BvuJmM"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UfrTRlDjHdpm"
   },
   "source": [
    "### **(b) Train the model with different strategies:** (3 points)\n",
    "###  **#1.** Train three models, one without adversarial training, one with adversarial training using `fgsm`, and last one with adversarial training using `pgd`. \n",
    "\n",
    "* Use attack budget `epsilon` of 0.05.\n",
    "\n",
    "* Use a mini-batch of size 512, and train for 20 epochs with learning rate $10^{-2}$, and early stopping tolerance of $10^{-6}$. Report the loss in each case.\n",
    "\n",
    "* For `pgd`, use the value of step-size `alpha=0.01` and number of iterations `num_iter=100` when training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "2bb724b34389406fb659629f56fa22ab",
      "d3d44e3d94bf4d1ea8d70fa2afb5b39b",
      "ff46d3b5c3e04cc49d08549e6cddb3d9",
      "5c39bd5a47744bae8a4b7f105eb9ebf7",
      "ff2f912f79364e1ebf2a2f8e05101f26",
      "2e6eb73c9d894d52b2b0aa8d40832740",
      "7bae4cb614c046feb275518382b075ac",
      "41aadb001f854b98b07e3359823a26ec",
      "6cdfb2605a0246d084ef43b6ecf3a54d",
      "0729ba46176e40b498c2f208c1f2ecc7",
      "3e0a30a7b158473bbd4643dc41a10431",
      "f7e85b7d6a5844059e2164fc71d210f0",
      "79e83c2966e34952801b4111bbe6dad3",
      "1ac754efcc5c4e2cbee4393ae07c62af",
      "a43e08bdbed944f68d4db2d7afba6eb9",
      "18d3be4931ba461ea3e368125bbe2468",
      "82228aaf23b346a1ad6844cd3962fd38",
      "8a23af26e58841c4933136a5e3eef5f7",
      "24e71ab59de74840ac74200934f5c8ee",
      "bb8bd879ba0b4677bc554e65baae48fa",
      "13c81dc32c24496885c070b6a73207c6",
      "fcb99260bad34123800a584b5702ac93",
      "870cc06c2adf4049b75a207c6ccb9026",
      "b8c51d21588f4825ad031ab91f5262c0",
      "340f25d90caf4f088cd0349acebcc46f",
      "bd3b774d8f204fbd9ec70690111a8461",
      "fe49054cd7be49a38a44a7de1329aa8a",
      "8a353e6c2606469ab83bad405b99f571",
      "6ca023c7c41247e38f609bf90e9349cb",
      "ccce7124cd1e40ca8d3924817ee6d37a",
      "1fced3c132af4b5ab25a5552e51b77ef",
      "babf487834dd490f9c74ec32d56d784c",
      "8f469c1621f04d719ce6a176b53a9fc1"
     ]
    },
    "execution": {
     "iopub.execute_input": "2022-05-13T03:08:29.883635Z",
     "iopub.status.busy": "2022-05-13T03:08:29.883351Z",
     "iopub.status.idle": "2022-05-13T03:14:57.798446Z",
     "shell.execute_reply": "2022-05-13T03:14:57.797639Z",
     "shell.execute_reply.started": "2022-05-13T03:08:29.883587Z"
    },
    "id": "bq7g7Se_HdSM",
    "outputId": "83c25d28-4ec4-486b-ba24-ce51bdded883"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal Model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bb724b34389406fb659629f56fa22ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 2.2338333129882812\n",
      "Epoch: 1, Loss: 2.1168181896209717\n",
      "Epoch: 2, Loss: 1.8835252523422241\n",
      "Epoch: 3, Loss: 1.5130053758621216\n",
      "Epoch: 4, Loss: 1.162898302078247\n",
      "Epoch: 5, Loss: 0.9281675815582275\n",
      "Epoch: 6, Loss: 0.7788661122322083\n",
      "Epoch: 7, Loss: 0.6804671287536621\n",
      "Epoch: 8, Loss: 0.6123895049095154\n",
      "Epoch: 9, Loss: 0.5631710886955261\n",
      "Epoch: 10, Loss: 0.5262160897254944\n",
      "Epoch: 11, Loss: 0.49744927883148193\n",
      "Epoch: 12, Loss: 0.47444844245910645\n",
      "Epoch: 13, Loss: 0.4555703103542328\n",
      "Epoch: 14, Loss: 0.43976831436157227\n",
      "Epoch: 15, Loss: 0.42627251148223877\n",
      "Epoch: 16, Loss: 0.4145399034023285\n",
      "Epoch: 17, Loss: 0.40415456891059875\n",
      "Epoch: 18, Loss: 0.3948976993560791\n",
      "Epoch: 19, Loss: 0.3865472078323364\n",
      "Final Loss =  (19, 0.3865472078323364)\n",
      "----------------------------------------------\n",
      "FGSM Model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7e85b7d6a5844059e2164fc71d210f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 1.1881651878356934\n",
      "Epoch: 1, Loss: 1.085912823677063\n",
      "Epoch: 2, Loss: 1.022955298423767\n",
      "Epoch: 3, Loss: 0.9800436496734619\n",
      "Epoch: 4, Loss: 0.9480516910552979\n",
      "Epoch: 5, Loss: 0.9231178164482117\n",
      "Epoch: 6, Loss: 0.902167022228241\n",
      "Epoch: 7, Loss: 0.8834124207496643\n",
      "Epoch: 8, Loss: 0.8676431775093079\n",
      "Epoch: 9, Loss: 0.8519196510314941\n",
      "Epoch: 10, Loss: 0.8365588188171387\n",
      "Epoch: 11, Loss: 0.8221160769462585\n",
      "Epoch: 12, Loss: 0.8092756867408752\n",
      "Epoch: 13, Loss: 0.7955482602119446\n",
      "Epoch: 14, Loss: 0.7831981778144836\n",
      "Epoch: 15, Loss: 0.7711530327796936\n",
      "Epoch: 16, Loss: 0.7588655948638916\n",
      "Epoch: 17, Loss: 0.7472127079963684\n",
      "Epoch: 18, Loss: 0.7352306842803955\n",
      "Epoch: 19, Loss: 0.7243234515190125\n",
      "Final Loss =  (19, 0.7243234515190125)\n",
      "----------------------------------------------\n",
      "PGD Model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "870cc06c2adf4049b75a207c6ccb9026",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 1.549898624420166\n",
      "Epoch: 1, Loss: 0.7431626915931702\n",
      "Epoch: 2, Loss: 0.4415706396102905\n",
      "Epoch: 3, Loss: 0.3323846757411957\n",
      "Epoch: 4, Loss: 0.2652454376220703\n",
      "Epoch: 5, Loss: 0.2116582989692688\n",
      "Epoch: 6, Loss: 0.19527240097522736\n",
      "Epoch: 7, Loss: 0.1882706731557846\n",
      "Epoch: 8, Loss: 0.17313772439956665\n",
      "Epoch: 9, Loss: 0.1783478856086731\n",
      "Epoch: 10, Loss: 0.1602720469236374\n",
      "Epoch: 11, Loss: 0.15520521998405457\n",
      "Epoch: 12, Loss: 0.13474538922309875\n",
      "Epoch: 13, Loss: 0.1261933594942093\n",
      "Epoch: 14, Loss: 0.11934738606214523\n",
      "Epoch: 15, Loss: 0.11121489852666855\n",
      "Epoch: 16, Loss: 0.09578990191221237\n",
      "Epoch: 17, Loss: 0.08479103446006775\n",
      "Epoch: 18, Loss: 0.09344472736120224\n",
      "Epoch: 19, Loss: 0.09549833089113235\n",
      "Final Loss =  (19, 0.09549833089113235)\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#######\n",
    "# !!!! YOUR CODE HERE !!!!\n",
    "model = NN_Model()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print('Normal Model')\n",
    "model_normal, losses_normal = train_torch_model(model, 512, criterion, 20, X_train, y_train, lr = 0.01, tolerance = 1e-6,\n",
    "                                  adversarial_strategy=None, epsilon=0.05)\n",
    "print('Final Loss = ', losses_normal[-1])\n",
    "print('----------------------------------------------')\n",
    "\n",
    "print('FGSM Model')\n",
    "model_fgsm, losses_fgsm = train_torch_model(model, 512, criterion, 20, X_train, y_train, lr = 0.01, tolerance = 1e-6,\n",
    "                                  adversarial_strategy='fgsm', epsilon=0.05)\n",
    "print('Final Loss = ', losses_fgsm[-1])\n",
    "print('----------------------------------------------')\n",
    "\n",
    "\n",
    "print('PGD Model')\n",
    "model_pgd, losses_pgd = train_torch_model(model, 512, criterion, 20, X_train, y_train, lr = 0.01, tolerance = 1e-6,\n",
    "                                  adversarial_strategy='pgd', epsilon=0.05)\n",
    "print('Final Loss = ', losses_pgd[-1])\n",
    "print('----------------------------------------------')\n",
    "\n",
    "\n",
    "#######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y7rOVcnCuLPX"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ju_Ie0ouxiWD"
   },
   "source": [
    "### **#2.**Measuring performance: In this part we will be evaluate the trained models for different test scenarios. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k8chvaD8xiWM"
   },
   "source": [
    "### Print the accuracy of each of the three trained models on the clean test dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-05-13T03:24:56.568318Z",
     "iopub.status.busy": "2022-05-13T03:24:56.567590Z",
     "iopub.status.idle": "2022-05-13T03:24:57.880933Z",
     "shell.execute_reply": "2022-05-13T03:24:57.880188Z",
     "shell.execute_reply.started": "2022-05-13T03:24:56.568280Z"
    },
    "id": "gKvndMOogCkm",
    "outputId": "ca2f9257-a069-419c-f5f0-87a3bc4a2c60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal Model Accuracy =  0.9778\n",
      "FGSM Model Accuracy =  0.9778\n",
      "PGD Model Accuracy =  0.9778\n"
     ]
    }
   ],
   "source": [
    "#######\n",
    "# !!!! YOUR CODE HERE !!!!\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def get_accuracy(model, X_test_torch, y_test):\n",
    "  predictions_test = model(X_test_torch).to('cpu')\n",
    "  y_test_pred = torch.argmax(predictions_test, dim=1).numpy()\n",
    "  y_test = y_test.to('cpu')\n",
    "  return accuracy_score(y_test_pred, np.asarray(y_test, dtype=np.float32))\n",
    "\n",
    "accuracy_normal = get_accuracy(model_normal, X_test, y_test)\n",
    "print(\"Normal Model Accuracy = \", accuracy_normal)\n",
    "\n",
    "accuracy_fgsm = get_accuracy(model_fgsm, X_test, y_test)\n",
    "print(\"FGSM Model Accuracy = \", accuracy_fgsm)\n",
    "\n",
    "accuracy_pgd = get_accuracy(model_pgd, X_test, y_test)\n",
    "print(\"PGD Model Accuracy = \", accuracy_pgd)\n",
    "\n",
    "#######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ubzMsNqt-cXF"
   },
   "source": [
    "### **#3.** Using the same test dataset, perform adversarial attack to compute robust accuracy for each of the three models. Report the robust accuracy of each model for both:\n",
    "###(a) FGSM attack\n",
    "###(b) PGD attack\n",
    "\n",
    "### To create PGD attack examples, use `alpha=0.01`, `num_iter=100`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4z3T3nvR_M0o",
    "outputId": "45d4427e-00d3-47f2-94ba-8f88d7d76507"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FGSM Model Robust Accuracy =  0.843\n",
      "PGD Model Robust Accuracy =  0.9168\n"
     ]
    }
   ],
   "source": [
    "#######\n",
    "# !!!! YOUR CODE HERE !!!!\n",
    "\n",
    "delta_fgsm = fgsm(model, X_test, y_test, epsilon = 0.05)\n",
    "\n",
    "delta_pgd = pgd(model, X_test, y_test, alpha = 0.01, epsilon = 0.05, num_iter = 100)\n",
    "\n",
    "test_accuracy_fgsm = get_accuracy(model_fgsm, X_test + delta_fgsm, y_test)\n",
    "print(\"FGSM Model Robust Accuracy = \", test_accuracy_fgsm)\n",
    "\n",
    "test_accuracy_pgd = get_accuracy(model_pgd, X_test + delta_pgd, y_test)\n",
    "print(\"PGD Model Robust Accuracy = \", test_accuracy_pgd)\n",
    "\n",
    "\n",
    "#######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J0_L-VhvuMVq"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "25EbgUjC1JRK"
   },
   "source": [
    "### **(c) FastLin Bound Propagation Algorithm:** In this part, we will use Fast Linear (Fast-Lin) algorithm to get lower and upper bounds for each layer of the neural network. (2.5 points)\n",
    "\n",
    "**Note:** See Section 3.3 and algorithm 1 in the appendix (Section D: Algorithms) from this paper: \\\n",
    "[Weng etal, Towards Fast Computation of Certified Robustness for ReLU Networks, ICML 2018](https://arxiv.org/pdf/1804.09699.pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "616bu2CYtWaq"
   },
   "source": [
    "### Define a function `fast_linear_bound` that takes as input an ordered list of neural network model layers (`model_layers`), a single input example (`x`), attack budget (`epsilon`). Consider the $l_\\infty$ norm ball for this activity. Return a list of tuples of `pre-activation` lower and upper bound tensors for each layer. \n",
    "### Also keep in mind to set device when declaring new Tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T00:14:17.537413Z",
     "iopub.status.busy": "2022-05-17T00:14:17.536828Z",
     "iopub.status.idle": "2022-05-17T00:14:17.557304Z",
     "shell.execute_reply": "2022-05-17T00:14:17.556539Z",
     "shell.execute_reply.started": "2022-05-17T00:14:17.537374Z"
    },
    "id": "E_tpoAWpAgXL"
   },
   "outputs": [],
   "source": [
    "#######\n",
    "# !!! YOUR CODE HERE !!!\n",
    "def fast_linear_bound(model_layers, x, epsilon):\n",
    "  pass\n",
    "\n",
    "#######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "I7YfBUwZsrhq",
    "outputId": "049cde92-e6e8-48ae-b245-26bfbbc2e60b"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-775297fc5867>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mx_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_bounds_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfast_linear_bound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_model_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_epsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_bounds_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecimals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.0000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.7000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_bounds_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecimals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.3000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_bounds_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecimals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.0000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.4000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.2000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# !!DO NOT EDIT!!\n",
    "sample_epsilon = 0.2\n",
    "# unit test - 1\n",
    "x_1 = torch.tensor([[0.1, 0.9]], device=device)\n",
    "test_bounds_1 = fast_linear_bound(test_model_layers, x_1, sample_epsilon)\n",
    "assert torch.all(torch.eq(torch.round(test_bounds_1[0][0], decimals=2), torch.tensor([[0.0000, 0.7000]], device=device)))\n",
    "assert torch.all(torch.eq(torch.round(test_bounds_1[0][1], decimals=2), torch.tensor([[0.3000, 1.0000]], device=device)))\n",
    "assert torch.all(torch.eq(torch.round(test_bounds_1[1][0], decimals=2), torch.tensor([[0.0000, 1.4000, 1.2000]], device=device)))\n",
    "assert torch.all(torch.eq(torch.round(test_bounds_1[1][1], decimals=2), torch.tensor([[0.4500, 2.6000, 1.5000]], device=device)))\n",
    "assert torch.all(torch.eq(torch.round(test_bounds_1[2][0], decimals=2), torch.tensor([[3.100, -0.5000,  2.4000]], device=device)))\n",
    "assert torch.all(torch.eq(torch.round(test_bounds_1[2][1], decimals=2), torch.tensor([[6.25000, -0.2000, 4.0500]], device=device)))\n",
    "assert torch.all(torch.eq(torch.round(test_bounds_1[3][0], decimals=2), torch.tensor([[4.8000, 4.3000]], device=device)))\n",
    "assert torch.all(torch.eq(torch.round(test_bounds_1[3][1], decimals=2), torch.tensor([[8.7700, 8.9500]], device=device)))\n",
    "\n",
    "# unit test - 2\n",
    "x_2 = torch.tensor([[0.4, 0.5]], device=device)\n",
    "test_bounds_2 = fast_linear_bound(test_model_layers, x_2, sample_epsilon)\n",
    "assert torch.all(torch.eq(torch.round(test_bounds_2[0][0], decimals=2), torch.tensor([[0.2000, 0.3000]], device=device)))\n",
    "assert torch.all(torch.eq(torch.round(test_bounds_2[0][1], decimals=2), torch.tensor([[0.6000, 0.7000]], device=device)))\n",
    "assert torch.all(torch.eq(torch.round(test_bounds_2[1][0], decimals=2), torch.tensor([[0.4000, 1.0000, 0.8000]], device=device)))\n",
    "assert torch.all(torch.eq(torch.round(test_bounds_2[1][1], decimals=2), torch.tensor([[1.0000, 2.6000, 1.2000]], device=device)))\n",
    "assert torch.all(torch.eq(torch.round(test_bounds_2[2][0], decimals=2), torch.tensor([[0.4000, -0.3000, 0.8000]], device=device)))\n",
    "assert torch.all(torch.eq(torch.round(test_bounds_2[2][1], decimals=2), torch.tensor([[4.6000, 0.1000, 3.0000]], device=device)))\n",
    "assert torch.all(torch.eq(torch.round(test_bounds_2[3][0], decimals=2), torch.tensor([[1.2300, 0.4300]], device=device)))\n",
    "assert torch.all(torch.eq(torch.round(test_bounds_2[3][1], decimals=2), torch.tensor([[6.7000, 6.8000]], device=device)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m3Aus3g-5PjH"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FC9urVZrufqW"
   },
   "source": [
    "### **(d) Comparison of certification strategies** (2.5 points)\n",
    "### **#1.** Get the functions  `bound_propagation` and `binary_search` that you defined in HW3-Q3(d). Refactor the function `binary_search` so that it takes one additional input parameter: `bound_function` which represents a function that can be used to get the bounds, and modify your implementation of `binary_search` so that it uses the parameter `bound_function` for getting the bounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "fvpaTyWfvNyi"
   },
   "outputs": [],
   "source": [
    "#######\n",
    "# !!! YOUR CODE HERE !!!\n",
    "def bound_propagation(model_layers, x, epsilon):\n",
    "  bounds = []\n",
    "  l, u = (x - epsilon).clamp(min=0), (x + epsilon).clamp(max=1)\n",
    "  bounds.append((l, u))\n",
    "  for layer in model_layers:\n",
    "    if isinstance(layer, nn.Linear):\n",
    "    # calculating pre-activation bounds\n",
    "      l_ = (layer.weight.clamp(min=0) @ l.t() + layer.weight.clamp(max=0) @ u.t() + layer.bias[:,None]).t()\n",
    "      u_ = (layer.weight.clamp(min=0) @ u.t() + layer.weight.clamp(max=0) @ l.t() + layer.bias[:,None]).t()\n",
    "    \n",
    "    bounds.append((l_, u_))\n",
    "    \n",
    "    if isinstance(layer, nn.ReLU):\n",
    "    # calculating post-activation bounds\n",
    "      l_ = l_.clamp(min=0)\n",
    "      u_ = u_.clamp(min=0)\n",
    "\n",
    "    l, u = l_, u_\n",
    "    \n",
    "  # print(bounds)\n",
    "  return bounds\n",
    "\n",
    "# binary search to find optimum epsilon values\n",
    "def binary_search(epsilons, model_layers, X, y, num_classes, bond_function):\n",
    "  epsilon_list = []\n",
    "\n",
    "  # function to get return whether tested epsilon value satisfies the criteria for tensor 1\n",
    "  def criteria_1(model_layers, epsilon, X, y, num_classes, bond_function):\n",
    "    if bond_function == 'ibp':\n",
    "      bounds = bound_propagation(model_layers, X, epsilon)\n",
    "    i = 0\n",
    "\n",
    "    lower_bounds =  bounds[-1][0][i].detach().cpu().numpy()\n",
    "    upper_bounds = bounds[-1][1][i].detach().cpu().numpy()\n",
    "\n",
    "    flag = 0\n",
    "    for k in range(num_classes):\n",
    "      if y[i] != k:\n",
    "        criteria_value = lower_bounds[y[i]] - upper_bounds[k] \n",
    "        if criteria_value < 0:\n",
    "          flag = -1\n",
    "          break\n",
    "    return flag\n",
    "\n",
    "  # optimum epsilon value for tensor 1\n",
    "  start1 = 0\n",
    "  end1 = len(epsilons) - 1\n",
    "  flag1 = -1\n",
    "  while start1 <= end1:\n",
    "    mid = int((start1 + end1)/ 2)\n",
    "    if (criteria_1(model_layers, epsilons[mid], X, y, num_classes, bond_function) == 0 \n",
    "    and criteria_1(model_layers, epsilons[mid + 1], X, y, num_classes, bond_function) == -1):\n",
    "      epsilon_list.append(epsilons[mid])\n",
    "      flag1 = 0\n",
    "      break\n",
    "    elif (criteria_1(model_layers, epsilons[mid], X, y, num_classes, bond_function) == 0 \n",
    "          and criteria_1(model_layers, epsilons[mid + 1], X, y, num_classes, bond_function) == 0):\n",
    "      start1 = mid + 1\n",
    "    else:\n",
    "      end1 = mid - 1\n",
    "  # returning None if value not found\n",
    "  if flag1 == -1:\n",
    "    epsilon_list.append(None)\n",
    "\n",
    "  return epsilon_list\n",
    "\n",
    "#######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oZy27fBPvO-s"
   },
   "source": [
    "### **#2.** Now, consider the first example from `example_data_flattened`. For this example find the value of certified epsilon (using `binary_search`) using (1) IBP (2) Fast-Lin on the standard model that you trained in part (b). Compare your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LXAjAGsCwNnj",
    "outputId": "ff9e859b-b761-49a1-f4c3-d7ee736a2bf0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0033]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#######\n",
    "# !!! YOUR CODE HERE !!!\n",
    "epsilons = [x/10000 for x in range(1, 10000)]\n",
    "model_normal_layers = [layer for layer in model_normal.children()]\n",
    "\n",
    "binary_search(epsilons, model_normal_layers, example_data_flattened[0:1], example_labels[0:1], 10, 'ibp')\n",
    "#######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RG9NJzevwld4"
   },
   "source": [
    "### **#3.** Repeat the same activity as above but use the robust model that you trained on PGD adversarial example. Compare you results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BtgQUs03wxJD",
    "outputId": "a923dc13-b2cf-46f8-d89b-3774536ae5f3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0033]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#######\n",
    "# !!! YOUR CODE HERE !!!\n",
    "model_pgd_layers = [layer for layer in model_pgd.children()]\n",
    "\n",
    "binary_search(epsilons, model_pgd_layers, example_data_flattened[0:1], example_labels[0:1], 10, 'ibp')\n",
    "# We get the same robustness value for standard and PGD model for ibp.\n",
    "# We did not implement Fast-Lin\n",
    "#######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "452OpRGwD8vE"
   },
   "source": [
    "---\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0d983612b814860d9ab1dbb303f20bfc8fb4fb3419b27046d7bc1d14cf03c9f"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0729ba46176e40b498c2f208c1f2ecc7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "13c81dc32c24496885c070b6a73207c6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "18d3be4931ba461ea3e368125bbe2468": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1ac754efcc5c4e2cbee4393ae07c62af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_24e71ab59de74840ac74200934f5c8ee",
      "max": 20,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bb8bd879ba0b4677bc554e65baae48fa",
      "value": 20
     }
    },
    "1fced3c132af4b5ab25a5552e51b77ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "24e71ab59de74840ac74200934f5c8ee": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2bb724b34389406fb659629f56fa22ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d3d44e3d94bf4d1ea8d70fa2afb5b39b",
       "IPY_MODEL_ff46d3b5c3e04cc49d08549e6cddb3d9",
       "IPY_MODEL_5c39bd5a47744bae8a4b7f105eb9ebf7"
      ],
      "layout": "IPY_MODEL_ff2f912f79364e1ebf2a2f8e05101f26"
     }
    },
    "2e6eb73c9d894d52b2b0aa8d40832740": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "340f25d90caf4f088cd0349acebcc46f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ccce7124cd1e40ca8d3924817ee6d37a",
      "max": 20,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1fced3c132af4b5ab25a5552e51b77ef",
      "value": 20
     }
    },
    "3e0a30a7b158473bbd4643dc41a10431": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "41aadb001f854b98b07e3359823a26ec": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5c39bd5a47744bae8a4b7f105eb9ebf7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0729ba46176e40b498c2f208c1f2ecc7",
      "placeholder": "​",
      "style": "IPY_MODEL_3e0a30a7b158473bbd4643dc41a10431",
      "value": " 20/20 [00:04&lt;00:00,  4.71it/s]"
     }
    },
    "6ca023c7c41247e38f609bf90e9349cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6cdfb2605a0246d084ef43b6ecf3a54d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "79e83c2966e34952801b4111bbe6dad3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_82228aaf23b346a1ad6844cd3962fd38",
      "placeholder": "​",
      "style": "IPY_MODEL_8a23af26e58841c4933136a5e3eef5f7",
      "value": "100%"
     }
    },
    "7bae4cb614c046feb275518382b075ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "82228aaf23b346a1ad6844cd3962fd38": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "870cc06c2adf4049b75a207c6ccb9026": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b8c51d21588f4825ad031ab91f5262c0",
       "IPY_MODEL_340f25d90caf4f088cd0349acebcc46f",
       "IPY_MODEL_bd3b774d8f204fbd9ec70690111a8461"
      ],
      "layout": "IPY_MODEL_fe49054cd7be49a38a44a7de1329aa8a"
     }
    },
    "8a23af26e58841c4933136a5e3eef5f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8a353e6c2606469ab83bad405b99f571": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8f469c1621f04d719ce6a176b53a9fc1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a43e08bdbed944f68d4db2d7afba6eb9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_13c81dc32c24496885c070b6a73207c6",
      "placeholder": "​",
      "style": "IPY_MODEL_fcb99260bad34123800a584b5702ac93",
      "value": " 20/20 [00:11&lt;00:00,  1.71it/s]"
     }
    },
    "b8c51d21588f4825ad031ab91f5262c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8a353e6c2606469ab83bad405b99f571",
      "placeholder": "​",
      "style": "IPY_MODEL_6ca023c7c41247e38f609bf90e9349cb",
      "value": "100%"
     }
    },
    "babf487834dd490f9c74ec32d56d784c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bb8bd879ba0b4677bc554e65baae48fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "bd3b774d8f204fbd9ec70690111a8461": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_babf487834dd490f9c74ec32d56d784c",
      "placeholder": "​",
      "style": "IPY_MODEL_8f469c1621f04d719ce6a176b53a9fc1",
      "value": " 20/20 [07:33&lt;00:00, 22.70s/it]"
     }
    },
    "ccce7124cd1e40ca8d3924817ee6d37a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d3d44e3d94bf4d1ea8d70fa2afb5b39b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2e6eb73c9d894d52b2b0aa8d40832740",
      "placeholder": "​",
      "style": "IPY_MODEL_7bae4cb614c046feb275518382b075ac",
      "value": "100%"
     }
    },
    "f7e85b7d6a5844059e2164fc71d210f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_79e83c2966e34952801b4111bbe6dad3",
       "IPY_MODEL_1ac754efcc5c4e2cbee4393ae07c62af",
       "IPY_MODEL_a43e08bdbed944f68d4db2d7afba6eb9"
      ],
      "layout": "IPY_MODEL_18d3be4931ba461ea3e368125bbe2468"
     }
    },
    "fcb99260bad34123800a584b5702ac93": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fe49054cd7be49a38a44a7de1329aa8a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ff2f912f79364e1ebf2a2f8e05101f26": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ff46d3b5c3e04cc49d08549e6cddb3d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_41aadb001f854b98b07e3359823a26ec",
      "max": 20,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6cdfb2605a0246d084ef43b6ecf3a54d",
      "value": 20
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
